Format:
#. Query string
    R: Reason for testing query
    C\E: Comment or explanation on how we improved our results or didn't need to

1. ics majors
    R: (Evaluating ranking performance: finding a particular website with general word query)
    C\E: Even with many possible results, the time it takes to search for the query is < 300 ms. At first we only did a tf-Idf calculation for our queries. This results in us having a fast query execution but a loss in accuracy. To mitigate this we calculate a cosine similarity if tf-idf scores are high.

2. contact support
    R: Evaluating ranking performance: unknown what resource user is specifically searching for
    C\E: When a user searches for a vague query, the weight of different html tags play a vital role in displaying the most relevant information, which is why we implemented weights as specified in the assignment’s directions. This, combined with the tf-idf calculation and cosine similarity, allows for fast and accurate results. 

3. stdent clubbs
    R: Evaluating ranking performance: misspelling
    C\E: This query started off poorly because our search engine could not handle spelling errors. It would look them up as is. To improve it, we decided to implement autocorrection. After researching different libraries, we found that the fastest and most efficient for our use case is autocorrect (https://pypi.org/project/autocorrect/), which can take in an entire phrase and fix the spelling errors. HOWEVER, we also realized that proper nouns would be ‘corrected’ to other existing words. For example, “Pattis” to “parts.” We decided that correctly spelled accuracy is more important than fixing misspelled accuracy and decided not to implement a spellchecker. 

4. best informatics profs
    R: Evaluating ranking performance: subjective (“best”) and abbreviated query (“professors”)
    C\E: This query is both abbreviated and non-specific, making it difficult to understand what exactly the user is searching for. This might be considered a misspelling by the search engine, which can cause it to slow down. In this case, the weight of different html tags play a vital role in displaying the most relevant information, which is why we implemented weights as specified in the assignment’s directions. This, combined with the tf-idf calculation and cosine similarity, allows for fast and accurate results. Also, since “best” is subjective to the user and the search engine has not been developed on things such as review sites, it is most efficient to simply provide results on informatics professors in general.

5. ics
    R: Evaluating runtime performance: broad topic with potentially many results
    C\E: When a user searches for a vague query, the weight of different html tags play a vital role in displaying the most relevant information, which is why we implemented weights as specified in the assignment’s directions. This, combined with the tf-idf calculation and cosine similarity, allows for fast and accurate results, even for a query such as “ics” that is large due to it being the name of a UCI school. 

6. workshops 
    R: Evaluating runtime performance: short/non-specific query
    C\E: This query is short and the user does not specify what type of workshops they are searching for. The lack of more descriptive words results in the search engine having to search and return every webpage that contains the word “workshops”, which can slow down the engine. Initially, we only did tf-idf calculations. This allowed for a faster speed but a loss in accuracy. To fix this, we calculate a cosine similarity when the tf-idf scores are high.

7. apple orange banana strawberry watermelon pineapple mango peach kiwi grapefruit lemon lime blueberry raspberry blackberry cherry papaya pomegranate 
    R: Evaluating runtime performance: long query with different words
    C\E: When a user searches for a long query with different words, the search engine takes a while to process each individual word. Unfortunately, we were not able to find a way to fix this problem. We even compared it to Google and they also take more than 300ms to calculate and find results for the query.

8. Llanfairpwllgwyngyllgogerychwyrndrobwllllantysiliogogogoch's
    R: Evaluating runtime performance: long, single word
    C\E: When a user searches for a long word, the search engine takes a while to process it and find results that match it. Unfortunately, we were not able to find a way to fix this problem. We even compared it to Google and they also take more than 300ms to calculate and find results for the query. 

9. pdf 
    R: Evaluating ranking and runtime performance: broad and searching specifically for websites containing pdf’s
    C\E: This query is short and the user does not specify which pdf’s they are searching for. The lack of more descriptive words results in the search engine having to search and return every webpage that contains the word “pdf” or pdf files, which can slow down the engine. We sought to provide pages in which the word appeared most frequently. Initially, we only did tf-idf calculations. This allowed for a faster speed but a loss in accuracy. To fix this, we calculate a cosine similarity when the tf-idf scores are high.

10. how to enroll
    R: Evaluating ranking and runtime performance: broad and searching for instructions
    C\E: This query implies that the user is searching for instructions on a task, and thus the query is context-based. This makes it difficult to find the most accurate results. There are many pages containing one or more of the query’s words, which can both slow down the search process and bring up inaccurate results. We sought to provide pages containing most to all of the words, and those in which they occurred frequently. Initially, we only did tf-idf calculations. This allowed for a faster speed but a loss in accuracy. To fix this, we calculate a cosine similarity when the tf-idf scores are high.

11. what hack uci club events happened between 2018 and 2021?
    R: Evaluating ranking performance: query better suited for relational databases
    C\E: The search engine is unable to give the exact correct desired results. However, this is understandable since the query is better suited for relational databases. Initially, we only did tf-idf calculations. This allowed for a faster speed but a loss in accuracy. To fix this, we calculate a cosine similarity when the tf-idf scores are high.

12. And or she his 
    R: test a query better suited for relational databases
    C\E: When a user searches for stop words such as and, or, she, or his, our search engine will produce results that use said stop words often from most to least used. We were able to achieve this by calculating cosine similarity and tf-idf scores.


Efficient Queries:
1. master of software engineering
2. wics club events
3. hackathon
4. chen li
5. ics course restrictions
6. informatics department faculty
7. honors program
8. undergraduate advising
9. dutt research group
10. ics course tutors
