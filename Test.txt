Format:
#. Query string
    R: Reason for testing query
    C\E: Comment or explanation on how we improved our results or didn't need to

1. ics majors
    R: finding a particular website with general word query
    C\E: At first we only did a tfIdf calculation for our queries. This results in us having a fast query execution but a loss in accuracy. To mitigate this we calculate a cosine similarity if tfidf scores are high.

2. contact support
    R: unknown what resource user is specifically searching for
    C\E: We didn't use weights at first but later we did which would be helpful for queries like this. When a user searches for a vague query, the weight of different html tags play a vital role in displaying the most relevant information

3. stdent clubbs
    R: misspelling
    C\E: 

4. best informatics profs
    R: subjective (“best”) and abbreviated query (“professors”)
    C\E: 

5. And, or, a, she, can
    R: See how our query handles words that show up in a lot of documents
    C\E: We at first didn't use a champion list therefore stop words like and too a fairly long time to load. To fix this we check if a term has a low idf if so we use a champion list.

6. ics
7. research
8. ai
    R: broad topic with potentially many results
    R: broad and short/non-specific query
    R: short and abbreviated query (“artificial intelligence”)
    C\E: Even with many possible results, the time it takes to search for the query is < 300 ms. This is because for single term queries we use a champion list. We look at a predefined set vs a undefined large set

10. how to enroll
    R: broad and searching for instructions
    C\E: 

11. find all ics professors with a phd
    R: test a query better suited for relational databases
    C\E: 

12. what hack uci events happened between 2018 and 2021?
    R: test a query better suited for relational databases
    C\E: 